{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD06j0cOdWTA+EzSGz7LLh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrZee24/PINN/blob/main/PINNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSi73-SoCt45"
      },
      "outputs": [],
      "source": [
        "pip install numpy torch matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from scipy.stats import gamma, beta, uniform\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from tqdm import tqdm\n",
        "!pip install py_vollib\n",
        "from py_vollib import black_scholes_merton as bsm\n",
        "from progressbar import ProgressBar\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "9EHXeW3WC4Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PINN class: Defines the neural network architecture with specified input dimension, hidden layers, hidden units, and output dimension. The activation function used is hyperbolic tangent (nn.Tanh())."
      ],
      "metadata": {
        "id": "sTSujOe8DDpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def thisS(q):\n",
        "    return gamma.ppf(q, a=100, scale=1)\n",
        "\n",
        "def thisK(q):\n",
        "    return uniform.ppf(q, 50, 200)\n",
        "\n",
        "def thisR(q):\n",
        "    return uniform.ppf(q, 0.01, 0.18)\n",
        "\n",
        "def thisD(q):\n",
        "    return uniform.ppf(q, 0.01, 0.18)\n",
        "\n",
        "def thisSigma(q):\n",
        "    return beta.ppf(q, a=2, b=5) + 0.001"
      ],
      "metadata": {
        "id": "dbnmIusXh1UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def this_extremes_S(q):\n",
        "    return uniform.ppf(q, 90, 110)\n",
        "num_increment = 12\n",
        "percentiles = pd.Series(np.linspace(0, 0.99, num_increment))\n",
        "S = percentiles.apply(thisS).tolist()\n",
        "K = percentiles.apply(thisK).tolist()\n",
        "q = percentiles.apply(thisD).tolist()\n",
        "t = np.array([.25, .5, .75, 1]).tolist()\n",
        "r = percentiles.apply(thisR).tolist()\n",
        "sigma = percentiles.apply(thisSigma).tolist()\n",
        "\n",
        "param_grid = {'S': S, 'K': K, 'q': q, 't': t, 'r': r, 'sigma': sigma}\n",
        "grid = ParameterGrid(param_grid)\n",
        "\n",
        "data = []\n",
        "for params in tqdm(grid, desc='Calcul des prix'):\n",
        "    price = bsm.black_scholes_merton(flag='c', S=params['S'], K=params['K'],\n",
        "                                     q=params['q'], t=params['t'], r=params['r'], sigma=params['sigma'])\n",
        "    # Ajoutez le prix au dictionnaire des paramètres\n",
        "    params['price'] = price\n",
        "    # Ajoutez le dictionnaire à la liste\n",
        "    data.append(params)\n",
        "# Convertissez la liste de dictionnaires en DataFrame\n",
        "fullDF = pd.DataFrame(data)\n",
        "# Enregistrez le DataFrame dans un fichier CSV\n",
        "fullDF.to_csv('dataFull.csv', index=False)\n",
        "print(fullDF.head())\n",
        "print(fullDF.tail())\n",
        "print(fullDF.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkP1VGH9iOO0",
        "outputId": "938cf4a3-4ec6-4a2e-abff-c64eefe783c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calcul des prix: 100%|██████████| 995328/995328 [00:05<00:00, 177036.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      K    S     q     r    sigma     t  price\n",
            "0  50.0  0.0  0.01  0.01  0.00100  0.25    0.0\n",
            "1  50.0  0.0  0.01  0.01  0.00100  0.50    0.0\n",
            "2  50.0  0.0  0.01  0.01  0.00100  0.75    0.0\n",
            "3  50.0  0.0  0.01  0.01  0.00100  1.00    0.0\n",
            "4  50.0  0.0  0.01  0.01  0.08819  0.25    0.0\n",
            "            K           S       q       r     sigma     t     price\n",
            "995323  248.0  124.722561  0.1882  0.1882  0.511316  1.00  3.015377\n",
            "995324  248.0  124.722561  0.1882  0.1882  0.706686  0.25  0.575184\n",
            "995325  248.0  124.722561  0.1882  0.1882  0.706686  0.50  3.027893\n",
            "995326  248.0  124.722561  0.1882  0.1882  0.706686  0.75  5.940339\n",
            "995327  248.0  124.722561  0.1882  0.1882  0.706686  1.00  8.688295\n",
            "Index(['K', 'S', 'q', 'r', 'sigma', 't', 'price'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PINN(nn.Module):\n",
        "    def __init__(self, input_dim, batch_size,hidden_layers, hidden_units, output_dim):\n",
        "        super(PINN, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        # Create a list to store the layers\n",
        "        layers = []\n",
        "\n",
        "        # Add the first hidden layer\n",
        "        layers.append(nn.Linear(input_dim, hidden_units))\n",
        "        layers.append(nn.ReLU())\n",
        "\n",
        "        # Add additional hidden layers\n",
        "        for _ in range(hidden_layers):\n",
        "            layers.append(nn.Linear(hidden_units, hidden_units))\n",
        "            layers.append(nn.Tanh())\n",
        "\n",
        "        # Add the output layer\n",
        "        layers.append(nn.Linear(hidden_units, output_dim))\n",
        "\n",
        "        # Create the sequential model\n",
        "        self.model = nn.Sequential(nn.Linear(64,64))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Ensure the input shape is correct\n",
        "        x = x.reshape(batch_size, input_dim)\n",
        "        # x should have shape (batch_size, input_dim), no need for unsqueeze here\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "2Xpbn-nzDCai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "black_scholes_pde function: Calculates the residual of the Black-Scholes equation using the model's predictions. It calculates the time and spatial derivatives using torch.autograd.grad and the input model, S (price of the underlying asset), and t (time)."
      ],
      "metadata": {
        "id": "wJtUU8MhDSNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def black_scholes_pde(model, S, t, sigma, r):\n",
        "    # Calculer les prédictions du modèle\n",
        "    V = model(torch.cat((S, t), dim=1))\n",
        "\n",
        "    # Créer un tenseur de grad_outputs de la même forme que V\n",
        "    grad_outputs = torch.ones_like(V)\n",
        "\n",
        "    # Calculer les gradients partiels\n",
        "    V_t = torch.autograd.grad(V, t, grad_outputs=grad_outputs, create_graph=True)[0]\n",
        "    V_S = torch.autograd.grad(V, S, grad_outputs=grad_outputs, create_graph=True)[0]\n",
        "\n",
        "    # Calculer le second gradient pour obtenir V_SS\n",
        "    grad_outputs_V_S = torch.ones_like(V_S)\n",
        "    V_SS = torch.autograd.grad(V_S, S, grad_outputs=grad_outputs_V_S, create_graph=True)[0]\n",
        "\n",
        "    # Calculer le résidu basé sur l'équation de Black-Scholes\n",
        "    residual = V_t + 0.5 * sigma ** 2 * S ** 2 * V_SS + r * S * V_S - r * V\n",
        "\n",
        "    return residual\n",
        "\n"
      ],
      "metadata": {
        "id": "KPSm_dozDNdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(model, S_init, t_init, u_init, S_boundary, t_boundary, u_boundary, collocation_points, sigma, r):\n",
        "    # Calculate residual error\n",
        "    residual_error = black_scholes_pde(model, collocation_points['S'], collocation_points['t'], sigma, r)\n",
        "    loss_residual = torch.mean(residual_error ** 2)  # Mean squared error (MSE) of residuals\n",
        "\n",
        "    inputs_init = torch.cat((t_init.unsqueeze(1), S_init.unsqueeze(1)), dim=1)\n",
        "\n",
        "\n",
        "\n",
        "    # Calculate initial condition error\n",
        "    # Create the input tensor for initial conditions\n",
        "    u_pred_init = model(inputs_init)\n",
        "    loss_initial = torch.mean((u_pred_init - u_init) ** 2)  # Mean squared error of initial conditions\n",
        "\n",
        "    # Calculate boundary condition error\n",
        "    # Create the input tensor for boundary conditions\n",
        "    u_boundary = torch.zeros((len(t_boundary), len(S_boundary)))\n",
        "    inputs_boundary = torch.cat((t_boundary.unsqueeze(1), S_boundary), dim=1)\n",
        "\n",
        "    u_pred_boundary = model(inputs_boundary).squeeze()\n",
        "\n",
        "    loss_boundary = torch.mean((u_pred_boundary - u_boundary) ** 2, dim=1)  # Mean squared error of boundary conditions\n",
        "\n",
        "    # Combine all losses\n",
        "    total_loss = loss_residual + loss_initial + loss_boundary\n",
        "    loss= total_loss.sum()\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "GvqiQeRAHpV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_pinn function: Trains the model using stochastic gradient descent (Adam optimizer) over a specified number of epochs. It samples random batches of inputs from the data (S and t), calculates the residual, and minimizes the mean squared error loss."
      ],
      "metadata": {
        "id": "kNXAeRFNDhbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_pinn(model, optimizer, fullDF, S_init, t_init, u_init, S_boundary, t_boundary, u_boundary, sigma, r, epochs, batch_size=64):\n",
        "    model.train()\n",
        "\n",
        "    if not isinstance(fullDF, pd.DataFrame):\n",
        "        fullDF = pd.DataFrame(fullDF)\n",
        "\n",
        "    # Convert the Pandas DataFrame to a NumPy array\n",
        "    fullDF = fullDF.values\n",
        "\n",
        "    S_collocation = fullDF[:, 0].reshape(-1, 1)\n",
        "    t_collocation = fullDF[:, 5].reshape(-1, 1)\n",
        "    u_collocation = fullDF[:, 6].reshape(-1, 1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Sample random batch points for S and t\n",
        "        idx = np.random.choice(len(fullDF), size=batch_size, replace=False)\n",
        "        S_batch = S_collocation[idx]\n",
        "        t_batch = t_collocation[idx]\n",
        "        u_batch = u_collocation[idx]\n",
        "\n",
        "        # Convertir les données en tenseurs PyTorch du bon type\n",
        "        S_batch = torch.tensor(S_batch, dtype=torch.float32)\n",
        "        t_batch = torch.tensor(t_batch, dtype=torch.float32)\n",
        "        u_batch = torch.tensor(u_batch, dtype=torch.float32)\n",
        "\n",
        "        # Concaténer les tenseurs d'entrée\n",
        "        input_tensor = torch.cat((t_batch.unsqueeze(1), S_batch.unsqueeze(1)), dim=1)\n",
        "\n",
        "        # Passer les données au modèle\n",
        "        u_pred = model(input_tensor)\n",
        "        u_pred = u_pred.view(-1, 1)\n",
        "        u_pred = u_pred[:batch_size]\n",
        "\n",
        "        # Calculer la perte\n",
        "        loss = torch.mean((u_pred - u_batch) ** 2)\n",
        "\n",
        "        # Réinitialiser les gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Rétropropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Mettre à jour les poids du modèle\n",
        "        optimizer.step()\n",
        "\n",
        "        # Afficher les informations sur l'entraînement\n",
        "        if epoch % 1000 == 0:\n",
        "            print(f\"Epoch: {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "hTyeFY-kDW-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exact_solution(S, t, sigma, r, K):\n",
        "    d1 = (torch.log(S / K) + (r + 0.5 * sigma ** 2) * t) / (sigma * torch.sqrt(t))\n",
        "    d2 = d1 - sigma * torch.sqrt(t)\n",
        "    C = S * torch.distributions.normal.Normal(0, 1).cdf(d1) - K * torch.exp(-r * t) * torch.distributions.normal.Normal(0, 1).cdf(d2)\n",
        "    return C"
      ],
      "metadata": {
        "id": "FdjV_ZC6IzsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main function: Defines the problem domain (range of S and t values), initializes the model and optimizer, trains the model, and then plots the predicted option prices at a specific time (t=0.5)."
      ],
      "metadata": {
        "id": "cOYYC3fBDpGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Define parameters\n",
        "    S_min, S_max = 0, 200\n",
        "    t_min, t_max = 0, 1\n",
        "    sigma = 0.2  # Volatility\n",
        "    r = 0.05    # Risk-free rate\n",
        "    K = 100  # Strike price (used in exact_solution)\n",
        "\n",
        "    # Create a grid of S and t values\n",
        "    S = torch.linspace(S_min, S_max, 1000)\n",
        "    t = torch.linspace(t_min, t_max, 1000)\n",
        "\n",
        "    # Prepare data for initial and boundary conditions\n",
        "    S_init = torch.linspace(S_min, S_max, 100)\n",
        "    t_init = torch.full((len(S_init),), t_min)\n",
        "    u_init = torch.zeros_like(S_init)\n",
        "\n",
        "    # Prepare data for collocation points\n",
        "    collocation_points = {'S': torch.linspace(S_min, S_max, 1000), 't': torch.linspace(t_min, t_max, 1000)}\n",
        "\n",
        "    # Prepare data for boundary conditions\n",
        "    S_boundary = torch.tensor([S_min, S_max])\n",
        "    t_boundary = torch.linspace(t_min, t_max, len(S_boundary))\n",
        "    S_boundary = S_boundary.view(2, 1)\n",
        "\n",
        "    u_boundary = torch.zeros((len(t_boundary), len(S_boundary)))\n",
        "\n",
        "\n",
        "    # Define model hyperparameters\n",
        "    input_dim = 2\n",
        "    hidden_layers = 10\n",
        "    hidden_units = 64\n",
        "    output_dim = 1\n",
        "\n",
        "    # Initialize the model\n",
        "    model = PINN(input_dim, hidden_layers, hidden_units, output_dim)\n",
        "    print(model.parameters())\n",
        "    # Define optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    epochs = 10000\n",
        "    batch_size = 64\n",
        "    train_pinn(model, optimizer, S_init, t_init, u_init, S_boundary, t_boundary, u_boundary, collocation_points, sigma, r, epochs, batch_size)\n",
        "\n",
        "    # Visualize the results\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Test the model on the entire domain for visualization\n",
        "        S_test = torch.linspace(S_min, S_max, 1000)\n",
        "        t_test = torch.full((1000,), 0.5)\n",
        "        inputs_test = torch.cat((t_test.unsqueeze(1), S_test.unsqueeze(1)), dim=1)\n",
        "\n",
        "        # Predict option prices using the trained model\n",
        "        V_pred = model(inputs_test).squeeze().numpy()\n",
        "        print(V_pred)\n",
        "        # Calculate exact solution for comparison\n",
        "        V_exact = exact_solution(S_test, t_test, sigma, r, K).numpy()\n",
        "    errors = V_pred - V_exact\n",
        "         # Plot the predicted and exact option prices\n",
        "    plt.figure()\n",
        "# Tracer les prédictions du modèle\n",
        "    plt.plot(S_test.numpy(), V_pred, label='Predicted V at t=0.5', color='blue')\n",
        "# Tracer la solution exacte\n",
        "    plt.plot(S_test.numpy(), V_exact, label='Exact V at t=0.5', color='red', linestyle='--')\n",
        "\n",
        "    plt.xlabel('S')  # Étiquette de l'axe x\n",
        "    plt.ylabel('Option Price')  # Étiquette de l'axe y\n",
        "    plt.title('Predicted vs. Exact Option Prices')  # Titre du graphique\n",
        "    plt.legend()  # Ajouter une légende\n",
        "    plt.plot(S_test.numpy(),V_pred , label='Error (V_pred )')\n",
        "    plt.xlabel('S')\n",
        "    plt.ylabel('Error')\n",
        "    plt.title('Errors between Predicted and Exact Option Prices')\n",
        "    plt.legend()\n",
        "\n",
        "# Afficher le graphique\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Tl03z1HDDma5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Charger le dataset à partir du fichier CSV\n",
        "    data = pd.read_csv('dataFull.csv')\n",
        "\n",
        "    # Extraire les données d'entrée et de sortie du dataset\n",
        "    X = data[['S', 'K', 'q', 'r', 'sigma', 't']].values\n",
        "    y = data['price'].values\n",
        "\n",
        "    # Fractionner les données en ensembles d'entraînement et de test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=7)\n",
        "\n",
        "    # Définir les valeurs initiales et aux bords\n",
        "    S_init = torch.tensor(X_train[:, 0]).float()\n",
        "    t_init = torch.tensor(X_train[:, 5]).float()\n",
        "    u_init = torch.tensor(y_train).float()\n",
        "    S_boundary = torch.tensor([X_train[:, 0].min(), X_train[:, 0].max()]).float()\n",
        "    t_boundary = torch.tensor([X_train[:, 5].min(), X_train[:, 5].max()]).float()\n",
        "    u_boundary = torch.zeros(2)  # À définir en fonction de votre problème\n",
        "\n",
        "    # Définir les hyperparamètres du modèle\n",
        "    input_dim = 64\n",
        "    hidden_layers = 2\n",
        "    hidden_units = 64\n",
        "    output_dim = 1\n",
        "    epochs = 10000\n",
        "\n",
        "    lr = 0.001\n",
        "\n",
        "    # Initialiser le modèle PINN\n",
        "    model = PINN(input_dim, hidden_layers, hidden_units, output_dim)\n",
        "\n",
        "    # Définir l'optimiseur\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Entraîner le modèle PINN\n",
        "    fullDF = pd.DataFrame(np.column_stack((X_train, y_train)), columns=['S', 'K', 'q', 'r', 'sigma', 't', 'price'])\n",
        "    train_pinn(model, optimizer, fullDF, S_init, t_init, u_init, S_boundary, t_boundary, u_boundary, sigma, r, epochs, batch_size=64)\n",
        "\n",
        "    # Évaluer le modèle sur l'ensemble de test\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(torch.tensor(X_test).float()).squeeze().numpy()\n",
        "\n",
        "    # Calculer l'erreur quadratique moyenne (MSE) sur l'ensemble de test\n",
        "    mse = np.mean((y_test - y_pred) ** 2)\n",
        "    print(f'Mean Squared Error (MSE) on test set: {mse}')\n",
        "\n",
        "    # Tracer les prédictions par rapport aux valeurs réelles\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(y_test, y_pred)\n",
        "    plt.xlabel('True Prices')\n",
        "    plt.ylabel('Predicted Prices')\n",
        "    plt.title('Comparison of True and Predicted Prices')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "collapsed": true,
        "id": "Htog6WG0qrwk",
        "outputId": "8d1aa77e-aaa0-4dc6-9260-c0aea234a44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "PINN.__init__() missing 1 required positional argument: 'output_dim'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-155-9ee367efe5de>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-155-9ee367efe5de>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Initialiser le modèle PINN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPINN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Définir l'optimiseur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: PINN.__init__() missing 1 required positional argument: 'output_dim'"
          ]
        }
      ]
    }
  ]
}